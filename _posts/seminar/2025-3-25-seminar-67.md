---
layout: post
title: "学术报告"
subtitle: 'LLM与Fuzzing结合技术分享'
date: 2025.3.18
host: "董雨昕"
digest: "本次组会主要通过两篇论文分享了LLM与Fuzzing相结合的技术"
permalink: /:categories/:year/:month/:day/:title
categories:
  - seminar
---
## LLM与Fuzzing结合技术分享

## 1. Augmenting Greybox Fuzzing with Generative AI
1.1 研究背景 
‌模糊测试的重要性‌：模糊测试通过自动生成测试用例来探索程序的执行路径和状态，对于发现软件漏洞至关重要。
‌现有方法的局限性‌：
‌基于突变的方法‌：通过随机或半随机修改已有输入生成测试用例，对于复杂结构的输入数据可能无法生成有意义的测试用例。
‌基于生成的方法‌：依赖于对输入数据格式或协议的理解，实现复杂且需要深入理解输入数据。
1.2 工作内容
CHATFUZZ框架‌：作者提出了一个新的模糊测试框架CHATFUZZ，通过生成式AI（LLM）增强灰盒模糊测试。
‌工作流程‌：
从种子池中挑选一个种子。
通过prompt引导LLM生成类似的输入。
灰盒模糊器评估生成的输入，保留能提高分支覆盖率的输入作为新种子。
1.3 选择超参数
‌模型选择‌：评估了Chat Model和Completion Model两种类型的LLM。
‌提示词设计‌：评估了三种不同的提示词配置对生成测试用例的影响。
‌效率相关参数‌：
max_tokens‌：模型响应的最大长度，平衡生成效率和测试用例质量。
n‌：模型响应中生成的独立回复数，影响单次查询成本和生成单个测试用例的平均成本。
temperature‌：模型响应内容的随机程度，影响生成的种子多样性和有效性。
1.4 效果评估
‌覆盖率‌：测量了CHATFUZZ对AFL++覆盖率的效果，验证了CHATFUZZ在提升分支覆盖率方面的有效性。
‌贡献率‌：评估了模型产生的有效种子占种子总数的比率，显示了CHATFUZZ对模糊测试的贡献。
‌安全性‌：评估了CHATFUZZ在检测bug方面的能力，验证了其在安全测试中的实用性。

## 2. LLAMAFUZZ: Large Language Model Enhanced Greybox Fuzzing
2.1 研究背景
‌解决现有变异策略的问题‌：使用LLM来增强fuzz的变异过程，学习数据格式信息的复杂模式，完成结构化数据的突变。
2.2 微调准备
‌数据收集‌：从真实的模糊测试过程中收集数据，包括触发新分支覆盖、新命中次数和bug的数据。
‌数据预处理‌：将二进制输入文件统一转为十六进制编码表示，文本输入数据不作额外处理。
2.3 LLM微调
‌监督微调‌：使预训练模型学习数据格式的底层结构和变异方法，通过设计的prompt强调格式关键字，使LLM能够进行有意义的突变。
2.4 LLM集成
‌异步通信方法‌：解决LLM与fuzzer之间的速度不匹配问题，通过发送和接收通道实现LLM与fuzzer的异步交互。
2.5 实验评估
bug触发数量‌：LLAMAFUZZ在Magma V1.2 benchmark上触发的bug数目明显优于其他fuzzer。
‌漏洞触发速度‌：LLAMAFUZZ在触发漏洞的速度上也表现出显著优势。
‌分支覆盖率‌：在真实场景下，LLAMAFUZZ在多个开源项目上相比AFL++展现出显著的覆盖率提升。





[本次组会内容下载链接](https://github.com/Lizhizhiyi/PPT/blob/main/files/20250325.pdf)
