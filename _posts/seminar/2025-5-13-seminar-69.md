---
layout: post
title: "学术报告"
subtitle: '基于大语言模型的模糊测试技术分享'
date: 2025.5.13
host: "王靖雯"
digest: "本次组会主要分享了《基于大语言模型的模糊测试研究综述》论文"
permalink: /:categories/:year/:month/:day/:title
categories:
  - seminar
---
## 基于大语言模型的模糊测试技术

## 1. 研究背景
大型语言模型（LLM）通过在海量语料上的预训练，具备小样本乃至零样本学习能力及强大推理能力，能够更好地理解测试用例与目标程序，从而克服传统深度学习在模糊测试中对训练数据依赖强、语义理解弱的固有缺陷

## 2. 主要方法
1. 测试输入生成：
微调：如FuzzGPT利用历史错误样本微调，CovRL通过覆盖率驱动的强化学习不断增强变异策略
提示工程：零样本/少样本示例、链式思维提示、自动提示（auto-prompt）等
传统算法融合：编译验证-反馈、程序静态分析（Bugsplainer、ChatTester、LLM4Fuzz）、变异算子和统计分析 基于大语言模型的模糊测
2. 缺陷检测：
测试断言生成：微调与提示引导LLM生成有效断言/预言
缺陷分析：VUL-GPT、AutoSD、LATTE等方法结合检索、调试信息及污点分析，AutoFL通过两步链式思维定位故障 基于大语言模型的模糊测试
3. 后模糊处理：
测试报告与程序修复：InferFix、APRFiT等微调方法生成高质量补丁；基于提示工程及程序分析的PyDex等结构化子集化处理，显著提升修复准确率

## 3. 应用现状
测试类型：灰盒测试占比74.5%，黑盒（13.7%）和白盒（11.8%）较少 基于大语言模型的模糊测试
测试对象与语言：覆盖开源软件与封装库；主流语言为Java、Python、C/C++，Solidity、Verilog等领域语言尚处探索阶段




[本次组会内容下载链接](https://github.com/Lizhizhiyi/PPT/blob/main/files/20250513.pdf)
